{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87403b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "55eb3c55",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f6fac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "\n",
    "data = digits[\"data\"]\n",
    "images = digits[\"images\"]\n",
    "target = digits[\"target\"]\n",
    "target_names = digits[\"target_names\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02410d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selected_items(target,data, images):#from 3,9\n",
    "    selectedIndex =  [i for i, v in enumerate(target) if v == 3 or v == 9]# finding the index of 3,9 from the targets\n",
    "    selectedTarget = [ v for i, v in enumerate(target) if i in selectedIndex]\n",
    "    selectedImages =  [ v for i, v in enumerate(images) if i in selectedIndex]\n",
    "    selectedData =  [ v for i, v in enumerate(data) if i in selectedIndex]\n",
    "    return selectedTarget,selectedData,selectedImages\n",
    "target_, data_, images_ = selected_items(target, data, images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b70553",
   "metadata": {},
   "outputs": [],
   "source": [
    "img =images_[0]\n",
    "assert 2 == len(img.shape)\n",
    "plt.figure()\n",
    "plt.gray()\n",
    "plt.imshow(img , interpolation = \"bicubic\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2d403902",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb2057b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = data_\n",
    "y_all = target_\n",
    "\n",
    "X_train, X_test, y_train, y_test =\\\n",
    "    model_selection.train_test_split(data_, target_,\n",
    "                                     test_size= 0.4, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fc575f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def features2d(data):\n",
    "    features = []\n",
    "    for i in range(len(data)):\n",
    "        features.append([6*data[i][26] + 5*data[i][29] + 4*data[i][18], # feature 1: high value for '9's\n",
    "                        12*data[i][36] + 8*data[i][21] + 10*data[i][4]])# feature 2: high value for '3's\n",
    "    x1 = [features[i][0] for i in range(len(features))]\n",
    "    x2 = [features[i][1] for i in range(len(features))]\n",
    "    return features, x1, x2\n",
    "\n",
    "features, x1, x2 = features2d(data_)\n",
    "y= [i for i in range(len(features))]\n",
    "\n",
    "plt.grid()\n",
    "plt.scatter(x1, x2, c=y_all, cmap=\"viridis\")\n",
    "plt.title(\"Feature Space\")\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.show()\n",
    "\n",
    "# Plot showing the feature space. Yellow points are '9's, purple points are '3's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73978f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features, train_x1, train_x2 = features2d(X_train)\n",
    "test_features, test_x1, test_x2 = features2d(X_test)\n",
    "\n",
    "def nearest_mean(training_features, training_labels, test_features):\n",
    "    training_x1 = [training_features[i][0] for i in range(len(training_features))]# class 9\n",
    "    training_x2 = [training_features[i][1] for i in range(len(training_features))]# class 3\n",
    "    # feature_ave1 = np.average(training_x1)\n",
    "    # feature_ave2 = np.average(training_x2)\n",
    "\n",
    "    predicted_labels =[]\n",
    "    for i in range(len(test_features)):\n",
    "        if test_features[i][0]>=100: # hand-picked criterion. Works better than nearest mean\n",
    "        # if abs(test_features[i][0]-feature_ave1) <= abs(test_features[i][1]-feature_ave2): # nearest mean\n",
    "            predicted_labels.append(1)\n",
    "        else:\n",
    "             predicted_labels.append(-1)\n",
    "                \n",
    "    return predicted_labels\n",
    "\n",
    "predicted_labels = nearest_mean(training_features, y_train, test_features)\n",
    "\n",
    "def errors(predicted_labels,true_labels):\n",
    "    fp=0\n",
    "    fn=0\n",
    "    for i in range(len(predicted_labels)):\n",
    "        if predicted_labels[i] == 1 and true_labels[i]==3:\n",
    "            fp +=1\n",
    "        elif predicted_labels[i] == -1 and true_labels[i]==9:\n",
    "            fn +=1\n",
    "    return print('The error is:{}'.format((fp+fn)/len(predicted_labels)))\n",
    "errors(predicted_labels,y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "785656cd",
   "metadata": {},
   "source": [
    "As you can see, the error rate of the hand-picked features is already very good.\n",
    "\n",
    "We could not get the visualization to work in time."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fb9c4e42",
   "metadata": {},
   "source": [
    "# Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e29cf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming variables and redefining functions for code compatibility\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "Y_train = np.array(y_train)\n",
    "Y_test = np.array(y_test)\n",
    "\n",
    "def features2d(x):\n",
    "    feature_1 = lambda inst: 6*inst[26] + 5*inst[29] + 4*inst[18]\n",
    "    feature_2 = lambda inst: 12*inst[36] + 8*inst[21] + 10*inst[4]\n",
    "\n",
    "    return np.array([[feature_1(inst), feature_2(inst)] for inst in x])\n",
    "\n",
    "def error_rate(predicted_labels, true_labels):\n",
    "    #  Count the entries where the predicted label differs from the expected label\n",
    "    f=0\n",
    "    for i in range(len(predicted_labels)):\n",
    "        if predicted_labels[i] != true_labels[i]:\n",
    "            f += 1\n",
    "\n",
    "    return f/true_labels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d86b0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_lda(training_features, training_labels):\n",
    "    mask_pos = np.array([t > 0 for t in training_labels])\n",
    "\n",
    "    N = training_labels.shape[0]\n",
    "    N_pos = training_labels[mask_pos].shape[0]\n",
    "\n",
    "    # calculate means for positive and negative label\n",
    "    mu_pos = np.sum(training_features[mask_pos], axis=0) / N_pos\n",
    "    mu_neg = np.sum(training_features[~mask_pos], axis=0) / (N - N_pos)\n",
    "    mu = np.array([mu_pos, mu_neg])\n",
    "\n",
    "    # calculate covariance matrix\n",
    "    vector_prod = lambda v: v * np.atleast_2d(v).T\n",
    "    covmat_pos = sum(map(lambda X: vector_prod(X - mu_pos), training_features[mask_pos])) / N_pos\n",
    "    covmat_neg = sum(map(lambda X: vector_prod(X - mu_neg), training_features[mask_pos])) / (N - N_pos)\n",
    "    covmat = covmat_pos + covmat_neg\n",
    "\n",
    "    # calculate the priors\n",
    "    p = np.array([N_pos / N, (N - N_pos) / N])\n",
    "\n",
    "    return mu, covmat, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae156ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_lda(mu, covmat, p, test_features):\n",
    "    c_inv = np.linalg.pinv(covmat)\n",
    "\n",
    "    mu_pos = np.atleast_2d(mu[0])\n",
    "    mu_neg = np.atleast_2d(mu[1])\n",
    "\n",
    "    beta = np.matmul(c_inv, mu_pos.T - mu_neg.T)\n",
    "    b = (np.matmul(mu_neg, np.matmul(c_inv, mu_neg.T)) - np.matmul(mu_pos, np.matmul(c_inv, mu_pos.T))) / 2\n",
    "\n",
    "    return np.sign(np.matmul(test_features, beta) + b).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca82d484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the '3' and '9' labels into '-1' and '1'\n",
    "Y_train_converted = np.vectorize(lambda i: i/3 - 2)(Y_train)\n",
    "Y_test_converted = np.vectorize(lambda i: i/3 - 2)(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12adf8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the LDA fit function to feature data and full data\n",
    "mu_feature, covmat_feature, p_feature = fit_lda(features2d(X_train), Y_train_converted)\n",
    "mu_full, covmat_full, p_full = fit_lda(X_train, Y_train_converted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cd4a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict training and test labels using LDA trained on\n",
    "# both the 2D feature space and the full pixel space\n",
    "predicted_training_labels_lda_feature = predict_lda(mu_feature, covmat_feature, p_feature, features2d(X_train))\n",
    "predicted_test_labels_lda_feature = predict_lda(mu_feature, covmat_feature, p_feature, features2d(X_test))\n",
    "\n",
    "predicted_training_labels_lda_full = predict_lda(mu_full, covmat_full, p_full, X_train)\n",
    "predicted_test_labels_lda_full = predict_lda(mu_full, covmat_full, p_full, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2702443",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Error rate of feature-trained LDA on training set: {:5.2f}%\".format(error_rate(predicted_training_labels_lda_feature, Y_train_converted)*100))\n",
    "print(\"Error rate of feature-trained LDA on test set:     {:5.2f}%\".format(error_rate(predicted_test_labels_lda_feature, Y_test_converted)*100))\n",
    "print()\n",
    "print(\"Error rate of fully trained LDA on training set:   {:5.2f}%\".format(error_rate(predicted_training_labels_lda_full, Y_train_converted)*100))\n",
    "print(\"Error rate of fully trained LDA on test set:       {:5.2f}%\".format(error_rate(predicted_test_labels_lda_full, Y_test_converted)*100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0b099063",
   "metadata": {},
   "source": [
    "We could not get the cross-validation and visualization to work in time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b602cb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare to LDA implementation by sklearn\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "clf_LDA = LDA()\n",
    "clf_LDA.fit(X_train, Y_train_converted)\n",
    "predicted_training_labels_sklearn_LDA = clf_LDA.predict(X_train)\n",
    "predicted_test_labels_sklearn_LDA = clf_LDA.predict(X_test)\n",
    "\n",
    "print(\"Error rate of sklearn-LDA on training set: {:5.2f}%\".format(error_rate(predicted_training_labels_sklearn_LDA, Y_train_converted)*100))\n",
    "print(\"Error rate of sklearn-LDA on test set:     {:5.2f}%\".format(error_rate(predicted_test_labels_sklearn_LDA, Y_test_converted)*100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2b4e88ea",
   "metadata": {},
   "source": [
    "# Exercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354a126c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_svm_step(training_features, training_labels, lam, beta, b, tau):\n",
    "    '''\n",
    "    Performs one step of the SVM gradient descent algorithm\n",
    "    '''\n",
    "    N = training_labels.shape[0]\n",
    "    mask_relu = np.array([training_labels[i] * (np.dot(training_features[i], beta) + b) < 1 for i in range(N)])\n",
    "\n",
    "    del_beta = beta - lam/N * np.matmul(training_features[mask_relu].T, training_labels[mask_relu])\n",
    "    del_b = - lam/N * np.sum(training_labels[mask_relu], axis=0)\n",
    "\n",
    "    new_beta = beta - tau * del_beta\n",
    "    new_b = b - tau*del_b\n",
    "\n",
    "    return new_beta, new_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5777981c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_svm(training_features, training_labels, lam, N_ITERATIONS=100):\n",
    "    D = training_features.shape[1]\n",
    "    # initial guess for beta and b\n",
    "    beta = np.random.rand(D)\n",
    "    b = np.random.rand()\n",
    "\n",
    "    # choosing the step size as a sequence converging to zero\n",
    "    tau = lambda t: 1 / (t + 1)\n",
    "\n",
    "    # perform gradient descent 100 times\n",
    "    for t in range(N_ITERATIONS):\n",
    "        beta, b = fit_svm_step(training_features, training_labels, lam, beta, b, tau(t))\n",
    "    \n",
    "    return beta, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53cfacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_svm(beta, b, test_features):\n",
    "    return np.sign(np.matmul(test_features, beta) + b).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd00bb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the SVM fit function to full pixel space with Lagrange multiplier 1\n",
    "beta_full, b_full = fit_svm(X_train, Y_train_converted, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9716f519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict training and test labels using SVM\n",
    "predicted_training_labels_svm = predict_svm(beta_full, b_full, X_train)\n",
    "predicted_test_labels_svm = predict_svm(beta_full, b_full, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1499e9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Error rate of SVM on training set: {:5.2f}%\".format(error_rate(predicted_training_labels_svm, Y_train_converted)*100))\n",
    "print(\"Error rate of SVM on test set:     {:5.2f}%\".format(error_rate(predicted_test_labels_svm, Y_test_converted)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf6c426",
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_error_of_svm(training_features, training_labels, test_features, test_labels, lam, N_ITERATIONS=100):\n",
    "    '''\n",
    "    Performs SVM gradient descent and calculates the error rate in each step\n",
    "    '''\n",
    "    errors = [0] * N_ITERATIONS\n",
    "\n",
    "    D = training_features.shape[1]\n",
    "    # initial guess for beta and b\n",
    "    beta = np.random.rand(D)\n",
    "    b = np.random.rand()\n",
    "\n",
    "    # choosing the step size as a sequence converging to zero\n",
    "    tau = lambda t: 1 / (t + 1)\n",
    "    # tau = lambda t: .01 # constant step size performs worse\n",
    "\n",
    "    for t in range(N_ITERATIONS):\n",
    "        beta, b = fit_svm_step(training_features, training_labels, lam, beta, b, tau(t))\n",
    "        predicted_labels = predict_svm(beta, b, test_features)\n",
    "        errors[t] = error_rate(predicted_labels, test_labels)\n",
    "    \n",
    "    return beta, b, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c942001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot error of SVM for Lagrange multiplier 1\n",
    "*_, errors = track_error_of_svm(X_train, Y_train_converted, X_test, Y_test_converted, 1)\n",
    "\n",
    "plt.plot(list(range(100)), errors)\n",
    "plt.grid()\n",
    "plt.title(\"Error rate of SVM over time\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Error rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a60a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(training_features, training_labels, r_validation = .2, N_ITERATIONS=100):\n",
    "    '''\n",
    "    Uses part of the training set to check which Lagrange multiplier works best.\n",
    "    '''\n",
    "    N = training_labels.shape[0]\n",
    "\n",
    "    # choose some fixed fraction of the training set to be the validation set\n",
    "    mask_validation = np.array([(t > (1 - r_validation)*N) for t in range(N)])\n",
    "    candidates = [10**k for k in range(-2, 3)]\n",
    "\n",
    "    best_error = float('inf')\n",
    "    best_candidate = [None, None, None] # will contain, lam, error, beta, and b\n",
    "\n",
    "    for lam in candidates:\n",
    "        beta, b = fit_svm(training_features[~mask_validation], training_labels[~mask_validation], lam, N_ITERATIONS)\n",
    "\n",
    "        predicted_labels = predict_svm(beta, b, training_features[mask_validation])\n",
    "        error = error_rate(predicted_labels, training_labels[mask_validation])\n",
    "\n",
    "        if error < best_error:\n",
    "            best_candidate = [lam, beta, b]\n",
    "            best_error = error\n",
    "    \n",
    "    return best_candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af346bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "lam_cv, *_ = cross_validation(X_train, Y_train)\n",
    "print(lam_cv) # print the parameter deemed best by the algorithm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "38666ecc",
   "metadata": {},
   "source": [
    "Apparently a low value for lambda is advantageous for this model\n",
    "\n",
    "We could not get the visualization to work in time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d559e1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare to SVM implementation by sklearn\n",
    "from sklearn import svm\n",
    "\n",
    "clf_SVM = svm.SVC()\n",
    "clf_SVM.fit(X_train, Y_train_converted)\n",
    "\n",
    "predicted_training_labels_sklearn_SVM = clf_SVM.predict(X_train)\n",
    "predicted_test_labels_sklearn_SVM = clf_SVM.predict(X_test)\n",
    "\n",
    "print(\"Error rate of sklearn-SVM on training set: {:5.2f}%\".format(error_rate(predicted_training_labels_sklearn_SVM, Y_train_converted)*100))\n",
    "print(\"Error rate of sklearn-SVM on test set:     {:5.2f}%\".format(error_rate(predicted_test_labels_sklearn_SVM, Y_test_converted)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ab35ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
